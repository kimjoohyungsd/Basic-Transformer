Above code is basic practice code for implementing Transformer blocks in Attention is all you need just a basic implementation
